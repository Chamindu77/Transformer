{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Create Word Embedding"
      ],
      "metadata": {
        "id": "KxbrHSbWYN-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DHeSYkhyf1t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "embeddings = {\n",
        "    \"The\": np.array([1.0, 0.0, 0.5]),\n",
        "    \"cat\": np.array([0.0, 1.0, 0.3]),\n",
        "    \"sat\": np.array([1.0, 1.0, 0.2])\n",
        "}\n",
        "\n",
        "# Create the input sequence as a matrix (shape: 3 x 2)\n",
        "X = np.stack([embeddings[\"The\"], embeddings[\"cat\"], embeddings[\"sat\"]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYXT44K96inz",
        "outputId": "5f8df93e-0873-4122-f569-0447699d9efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 0. , 0.5],\n",
              "       [0. , 1. , 0.3],\n",
              "       [1. , 1. , 0.2]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Create Q, K, V Matrices using Learnable Weights"
      ],
      "metadata": {
        "id": "vEArT9g5YUY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated weights (normally learned)\n",
        "W_Q = np.array([[1.0, 0.0, 0.5], [0.0, 1.0, 0.5],[0.0, 1.0, 0.5]])\n",
        "W_K = np.array([[1.0, 0.0, 0.5], [0.0, 1.0, 0.5],[0.0, 1.0, 0.5]])\n",
        "W_V = np.array([[0.5, 1.0, 0.2], [1.0, 0.5, 0.3],[1.0, 0.5, 0.1]])\n",
        "\n",
        "# Linear projections\n",
        "Q = X @ W_Q  # (3 x 3)\n",
        "K = X @ W_K  # (3 x 3)\n",
        "V = X @ W_V  # (3 x 3)"
      ],
      "metadata": {
        "id": "YMtsRYZV6stW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR86J8aR62XJ",
        "outputId": "0784728c-555f-45b9-8585-dbde1ec8b0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.  , 1.25, 0.25],\n",
              "       [1.3 , 0.65, 0.33],\n",
              "       [1.7 , 1.6 , 0.52]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmg79tMj63ZP",
        "outputId": "2fc3267c-c2e7-4896-d408-48d81990c287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.  , 0.5 , 0.75],\n",
              "       [0.  , 1.3 , 0.65],\n",
              "       [1.  , 1.2 , 1.1 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Compute Dot Products Between Queries and Keys"
      ],
      "metadata": {
        "id": "D6aFil8cYiRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = Q @ K.T  # (3 x 3)\n",
        "print(\"Dot product scores:\\n\", scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1_2H2kp8tgV",
        "outputId": "f409d9e0-bdc2-466d-ab53-d85da464bfaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot product scores:\n",
            " [[1.8125 1.1375 2.425 ]\n",
            " [1.1375 2.1125 2.275 ]\n",
            " [2.425  2.275  3.65  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Scale by âˆšd_k"
      ],
      "metadata": {
        "id": "wfnCsjxoYoZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dk = Q.shape[-1]\n",
        "scaled_scores = scores / np.sqrt(dk)"
      ],
      "metadata": {
        "id": "VZ_jfxHb85yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKgq8h0-8-qQ",
        "outputId": "b669fdf6-7e78-4c7a-c944-39ae0affbaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.04644736, 0.65673593, 1.4000744 ],\n",
              "       [0.65673593, 1.21965244, 1.31347186],\n",
              "       [1.4000744 , 1.31347186, 2.10732848]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Apply Softmax to Get Attention Weights"
      ],
      "metadata": {
        "id": "GRrtC3gPYw-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # for stability\n",
        "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
        "\n",
        "attention_weights = softmax(scaled_scores)\n",
        "print(\"Attention Weights:\\n\", attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMB-Ptg49K8f",
        "outputId": "636736de-52c0-40a3-986e-aa1da0fdab26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Weights:\n",
            " [[0.32242711 0.21836449 0.4592084 ]\n",
            " [0.21348029 0.37482567 0.41169404]\n",
            " [0.25345618 0.23242983 0.51411399]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Multiply by V to Get the Output"
      ],
      "metadata": {
        "id": "lttHItYXgkZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = attention_weights @ V\n",
        "print(\"Final Output:\\n\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y817GiLI-MHh",
        "outputId": "034d32d7-5869-421a-aa1d-6fcb9ae85a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Output:\n",
            " [[1.38695523 1.27970424 0.39145543]\n",
            " [1.40063353 1.16919751 0.39114344]\n",
            " [1.42960874 1.290482   0.40740516]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
        "\n",
        "# Step 1: Word embeddings (3 tokens, each with 3-dim embedding)\n",
        "X = np.array([\n",
        "    [1.0, 0.0, 1.0],  # \"The\"\n",
        "    [0.0, 1.0, 1.0],  # \"cat\"\n",
        "    [1.0, 1.0, 0.0]   # \"sat\"\n",
        "])  # Shape: (3 tokens x 3 dim)\n",
        "\n",
        "# Step 2: Use identity matrices for Q, K, V projections (for clarity)\n",
        "Wq = np.eye(3)  # (3 x 3)\n",
        "Wk = np.eye(3)\n",
        "Wv = np.eye(3)\n",
        "\n",
        "Q = X @ Wq  # (3 x 3)\n",
        "K = X @ Wk  # (3 x 3)\n",
        "V = X @ Wv  # (3 x 3)\n",
        "\n",
        "# Step 3: Compute scaled attention scores\n",
        "scores = Q @ K.T  # (3 x 3)\n",
        "\n",
        "# Optional: scale by sqrt(d_k), d_k = 3\n",
        "dk = Q.shape[-1]\n",
        "scaled_scores = scores / np.sqrt(dk)\n",
        "\n",
        "# Step 4: Create causal mask (lower triangular, so we can't see the future)\n",
        "seq_len = X.shape[0]\n",
        "mask = np.triu(np.ones((seq_len, seq_len)) * -np.inf, k=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "qYFhMeZA-Nfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply mask\n",
        "masked_scores = scaled_scores + mask"
      ],
      "metadata": {
        "id": "cYMxL2HICyra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE3Dw5JKC-Qq",
        "outputId": "36730002-d550-497b-fa2d-e86b01d1fe8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.15470054,       -inf,       -inf],\n",
              "       [0.57735027, 1.15470054,       -inf],\n",
              "       [0.57735027, 0.57735027, 1.15470054]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Softmax over masked scores\n",
        "attn_weights = softmax(masked_scores)\n",
        "attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCcdZlAGDA-l",
        "outputId": "e7a821d5-2f04-4c1e-a09c-11163c4dded2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        ],\n",
              "       [0.35954252, 0.64045748, 0.        ],\n",
              "       [0.26445846, 0.26445846, 0.47108308]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Compute attention output\n",
        "output = attn_weights @ V  # (3 x 3)\n",
        "\n",
        "# Print everything\n",
        "print(\"Q:\\n\", Q)\n",
        "print(\"K:\\n\", K)\n",
        "print(\"V:\\n\", V)\n",
        "print(\"Masked Attention Weights:\\n\", attn_weights)\n",
        "print(\"Masked Self-Attention Output:\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd5C4JQeCw-T",
        "outputId": "3a4d4c20-e57b-4f7e-c132-62e7e27bb456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q:\n",
            " [[1. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 1. 0.]]\n",
            "K:\n",
            " [[1. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 1. 0.]]\n",
            "V:\n",
            " [[1. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 1. 0.]]\n",
            "Masked Attention Weights:\n",
            " [[1.         0.         0.        ]\n",
            " [0.35954252 0.64045748 0.        ]\n",
            " [0.26445846 0.26445846 0.47108308]]\n",
            "Masked Self-Attention Output:\n",
            " [[1.         0.         1.        ]\n",
            " [0.35954252 0.64045748 1.        ]\n",
            " [0.73554154 0.73554154 0.52891692]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SP8mu8snDE7g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}